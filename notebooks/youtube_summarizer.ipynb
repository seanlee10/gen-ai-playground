{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanlee10/notebooks/gen-ai-playground/blob/main/youtube_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPDLYd1T2nLn",
        "outputId": "aff6b49e-a0cd-429d-b71a-b23e8c37dea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU yt-dlp boto3 deepgram-sdk langchain-aws langchain-core langchain-groq langchain-nvidia-ai-endpoints langchain-anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Download Youtube video as MP3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT8Dl-sO2tB5",
        "outputId": "554681d2-a57a-4d98-c491-9502bf2cef01"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import time\n",
        "import boto3\n",
        "import requests\n",
        "from yt_dlp import YoutubeDL\n",
        "from google.colab import userdata\n",
        "\n",
        "AWS_ACCESS_KEY_ID = userdata.get('aws_access_key_id')\n",
        "AWS_SECRET_ACCESS_KEY = userdata.get('aws_secret_access_key')\n",
        "AWS_REGION = \"<<YOUR_REGION>>\"\n",
        "BUCKET_NAME = \"<<YOUR_BUCKET_NAME>>\"\n",
        "\n",
        "session = boto3.Session(\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
        "    region_name=AWS_REGION\n",
        ")\n",
        "\n",
        "video_url = input('Enter the video url: ')\n",
        "\n",
        "def to_snake_case(string):\n",
        "    # Replace any non-word character with an underscore\n",
        "    s1 = re.sub(r'[^\\w]+', '_', string)\n",
        "    # Insert an underscore before any uppercase letter which is preceded by a lowercase letter or number\n",
        "    s2 = re.sub(r'([a-z0-9])([A-Z])', r'\\1_\\2', s1)\n",
        "    # Convert to lowercase\n",
        "    return s2.lower()\n",
        "\n",
        "def download_audio(link):\n",
        "  with YoutubeDL({'extract_audio': True, 'format': 'bestaudio', 'outtmpl': 'download.mp3'}) as video:\n",
        "    info_dict = video.extract_info(link, download = True)\n",
        "    video_title = to_snake_case(info_dict['title'])\n",
        "    print(video_title)\n",
        "    video.download(link)\n",
        "    print(\"Successfully Downloaded - see local folder on Google Colab\")\n",
        "\n",
        "    return video_title\n",
        "\n",
        "video_title = download_audio(video_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Create Transcribe Job with Amazon Transcribe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8lQ-sKmUOzz",
        "outputId": "c0ce425f-4d0d-4f62-82fa-ff81ed7e942a"
      },
      "outputs": [],
      "source": [
        "s3 = session.client('s3')\n",
        "transcribe = session.client('transcribe')\n",
        "\n",
        "local_file = 'download.mp3'\n",
        "s3_file = f\"{video_title}.mp3\"\n",
        "\n",
        "def upload_to_s3(local_file, BUCKET_NAME, s3_file):\n",
        "    s3 = session.client('s3')\n",
        "\n",
        "    try:\n",
        "        s3.upload_file(local_file, BUCKET_NAME, s3_file)\n",
        "        print(f\"Upload Successful: {local_file} uploaded to {BUCKET_NAME}/{s3_file}\")\n",
        "        return True\n",
        "    except FileNotFoundError:\n",
        "        print(f\"The file {local_file} was not found\")\n",
        "        return False\n",
        "\n",
        "uploaded = upload_to_s3(local_file, BUCKET_NAME, s3_file)\n",
        "\n",
        "if uploaded:\n",
        "    print(\"File upload completed\")\n",
        "else:\n",
        "    print(\"File upload failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCsLRPIjUNld",
        "outputId": "22f67074-b91f-4609-ed78-90e29bf71f2c"
      },
      "outputs": [],
      "source": [
        "def create_transcribe_job(job_name, audio_file_uri):\n",
        "    response = transcribe.start_transcription_job(\n",
        "        TranscriptionJobName=job_name,\n",
        "        LanguageCode='en-US',  # Specify the language code\n",
        "        MediaFormat='mp3',  # Specify the media format (e.g., mp3, wav)\n",
        "        Media={\n",
        "            'MediaFileUri': audio_file_uri\n",
        "        },\n",
        "        Settings={\n",
        "            'ShowSpeakerLabels': True,\n",
        "            'MaxSpeakerLabels': 3\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return response\n",
        "\n",
        "# Example usage\n",
        "job_name = video_title\n",
        "audio_file_uri = f\"s3://{BUCKET_NAME}/{s3_file}\"\n",
        "\n",
        "response = create_transcribe_job(job_name, audio_file_uri)\n",
        "print(f\"Transcription job created: {response['TranscriptionJob']['TranscriptionJobName']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Wait for Transcription Job to finish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LMMgZRR6gCsN",
        "outputId": "2c3ebf2e-e96d-420e-f47a-1337d00b8382"
      },
      "outputs": [],
      "source": [
        "job_status = response['TranscriptionJob']['TranscriptionJobStatus']\n",
        "\n",
        "while job_status != \"COMPLETED\":\n",
        "\n",
        "    response = transcribe.get_transcription_job(\n",
        "        TranscriptionJobName=job_name\n",
        "    )\n",
        "\n",
        "\n",
        "    job_status = response['TranscriptionJob']['TranscriptionJobStatus']\n",
        "    time.sleep(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL2Me6YChA2f",
        "outputId": "c4a8dd71-c777-4dd1-c632-2841134e8e92"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_transcription_result(job_name):\n",
        "    job = transcribe.get_transcription_job(\n",
        "        TranscriptionJobName=job_name\n",
        "    )\n",
        "\n",
        "    transcript_uri = job['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
        "\n",
        "    print(transcript_uri)\n",
        "    # Parse S3 URI to get bucket and key\n",
        "    from urllib.parse import urlparse\n",
        "    parsed_uri = urlparse(transcript_uri)\n",
        "    bucket = parsed_uri.netloc\n",
        "    key = parsed_uri.path.lstrip('/')\n",
        "\n",
        "    # Download the transcription file\n",
        "    response = requests.get(transcript_uri)\n",
        "    if response.status_code == 200:\n",
        "        transcript = response.json()\n",
        "\n",
        "        # Extract the transcription text\n",
        "        transcription_text = transcript['results']['transcripts'][0]['transcript']\n",
        "        return transcription_text\n",
        "    else:\n",
        "        return f\"Failed to download transcript. Status code: {response.status_code}\"\n",
        "\n",
        "transcription = get_transcription_result(job_name)\n",
        "\n",
        "# uncomment this block if you want to keep the transcript as file\n",
        "# with open(f\"{video_title}.txt\", \"w\") as text_file:\n",
        "#     text_file.write(transcription)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhTKWKcB3DFw",
        "outputId": "590f01df-32c1-46ae-ee8b-47fd7de2488f"
      },
      "outputs": [],
      "source": [
        "from langchain_aws import ChatBedrock\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# BEDROCK_CLIENT = session.client(\"bedrock-runtime\", 'ap-northeast-2')\n",
        "# llm = ChatBedrock(\n",
        "#     model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
        "#     model_kwargs=dict(temperature=0),\n",
        "#     client=BEDROCK_CLIENT,\n",
        "# )\n",
        "\n",
        "# os.environ[\"GROQ_API_KEY\"] = userdata.get('groq')\n",
        "# llm = ChatGroq(\n",
        "#     model=\"llama-3.1-70b-versatile\",\n",
        "#     temperature=0,\n",
        "#     max_tokens=None,\n",
        "# )\n",
        "\n",
        "# os.environ[\"NVIDIA_API_KEY\"] = userdata.get('nvidia')\n",
        "# llm = ChatNVIDIA(\n",
        "#     model=\"nvidia/llama-3.1-nemotron-70b-instruct\"\n",
        "# )\n",
        "\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get('anthropic')\n",
        "\n",
        "llm = ChatAnthropic(\n",
        "    model=\"claude-3-5-sonnet-latest\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "template = \"\"\"\n",
        "I'd like to write a blog post with the insights from the provided transcript. list all important points with supporting quotes.\n",
        "\n",
        "<transcript>\n",
        "{TRANSCRIPT}\n",
        "</transcript>\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = prompt | llm | (lambda x: x.content)\n",
        "\n",
        "summary = chain.invoke({\"TRANSCRIPT\": transcription})\n",
        "print(summary)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyODQAolZPbG2QKu1HSe60Ns",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
