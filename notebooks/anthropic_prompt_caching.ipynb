{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCPYrguJFnFiupzxBXTJlt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanlee10/gen-ai-playground/blob/main/notebooks/anthropic_prompt_caching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "zSKLy100RbDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU yt-dlp anthropic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPXEVlQAUTED",
        "outputId": "84e210d0-8116-4436-e699-16265749674f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.9/207.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieve Content from Notion"
      ],
      "metadata": {
        "id": "jZ-zklEPSwoR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CmUpFMcdRVGf"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import anthropic\n",
        "from google.colab import userdata\n",
        "\n",
        "auth_token = userdata.get('notion')\n",
        "\n",
        "client = anthropic.Anthropic(\n",
        "    api_key=userdata.get('anthropic')\n",
        ")\n",
        "\n",
        "def fetch_content(page_id):\n",
        "  # URL of the API endpoint\n",
        "  url = f\"https://api.notion.com/v1/blocks/{page_id}/children?page_size=100\"\n",
        "\n",
        "  # Headers including the authorization\n",
        "  headers = {\n",
        "      \"Authorization\": f\"Bearer {auth_token}\",\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Notion-Version\": \"2022-02-22\"\n",
        "  }\n",
        "\n",
        "  try:\n",
        "      # Make the GET request\n",
        "      response = requests.get(url, headers=headers)\n",
        "      content = \"\"\n",
        "\n",
        "      # Check if the request was successful\n",
        "      if response.status_code == 200:\n",
        "          # Request was successful\n",
        "          data = response.json()  # Assuming the response is in JSON format\n",
        "\n",
        "          for block in data['results']:\n",
        "            if block['type'] == 'paragraph':\n",
        "              content += block['paragraph']['rich_text'][0]['text']['content']\n",
        "\n",
        "          print(\"Request successful!\")\n",
        "          return content\n",
        "      else:\n",
        "          # Request failed\n",
        "          print(f\"Request failed with status code: {response.status_code}\")\n",
        "          print(\"Response content:\", response.text)\n",
        "\n",
        "  except requests.exceptions.RequestException as e:\n",
        "      # Handle any exceptions that occurred during the request\n",
        "      print(f\"An error occurred: {e}\")\n",
        "      raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Retrival of a Notion Page"
      ],
      "metadata": {
        "id": "dVBzHj58W2RX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the Page ID with your own\n",
        "content = fetch_content(\"17d11dd8536b804f81c0e280dd688f8f\")\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2EKSC-aSdj6",
        "outputId": "282d6832-a936-4d74-c4cd-ba606dd0be1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request successful!\n",
            "What they achieved is is singular. Never been done before. Just to put in perspective, 100,000 GPUs, that’s, you know, easily the fastest supercomputer on the planet as one cluster. A supercomputer, that you would build would take normally 3 years to plan Right. And then they deliver the equipment, and it takes 1 year to get it all working. Yes. We’re talking about 19 days. Jensen, nice glasses. Hey. Yeah. You too. It’s great to be with you. Yeah. I got my ugly glasses on just like you. Come on. Those aren’t ugly. This is pretty good. They’re Do you like the red ones better? There’s something only your family could love. Well, it’s Friday, October 4th. We’re at the NVIDIA headquarters just down the street from Altimeter. Welcome. Thank you. Thank you. And we have our investor meeting, our annual investor meeting on Monday where we’re gonna debate all the consequences of AI, how fast we’re scaling intelligence, and I couldn’t think of anybody better really to kick it off with than you. Appreciate that. As both a shareholder, as a thought partner, kicking ideas back and forth, you really make us smarter, and we’re just grateful for the friendship so thanks for being here. Happy to be here. You know, this year the the theme is scaling intelligence to AGI. It’s pretty mind boggling that when we did this 2 years ago, we did it on the age of AI and that was 2 months before chat gpt. Mhmm. And to think about all this change. So I thought we would kick it off with a thought experiment and maybe a prediction. Yep. If I colloquially think of AGI as that personal assistant in my pocket, If I think of AGI as that colloquial assistant in my pocket used to it. Exactly. Yep. You know, that knows everything about me. Mhmm. That has perfect memory of me, that can communicate with me, that can book a hotel for me, or maybe book a doctor’s appointment for me. Mhmm. When you look at the rate of change in the world today, when do you think we’re going to have that personal assistant in our pocket? Soon in some form. Yeah. Yeah. Soon in some form. And that that, that assistant will will get better over time. That’s the beauty of technology as we know it. And so so I think in the beginning it’ll it’ll be quite useful, but not perfect, and then it gets more and more perfect over time like all technology. When we look at the rate of change, I think Elon has said the only thing that really matters is rate of change. It sure it sure feels to us like the rate of change has accelerated dramatically as the fastest rate of change we’ve ever seen on these questions because we’ve been around the rim like you on on AI for a decade now, you you even longer. Is this the fastest rate of change you’ve seen in your career? It is because we’ve reinvented computing. You know, a lot of this is happening because we we drove the marginal cost of computing down by a 100000 x over the course of 10 years. Moore’s law would have been about a 100 x. Yeah. And and we did it we did it in several ways. We did it by, 1, introducing accelerated computing, taking taking what has worked that is, not very not very effective on CPUs and put it on top of GPUs. We did it by, inventing new numerical precisions. We did it by new architectures, inventing the tensor core, the way systems are for are formulated, m v link, added, insanely insane insanely fast memories HBM, and, scaling things up with, NVLink and InfiniBand, and working across the entire stack. Right? Basically, everything that that I described about how NVIDIA does things, led to a super Moore’s law rate of innovation. Now the thing that’s that’s really make it amazing is that that as a result of that, we went from human programming to machine learning. And the amazing thing about machine learning is that machine learning can learn pretty fast Right. As it turns out. And so as we as we reformulated the way we distribute computing, you know, we we did a lot of, you know, parallelism of all kinds. Right? Tensor parallelism, pipeline parallelism, parallelism of all kinds. And and, we became good at good at, inventing new algorithms on top of that and, new training methods and and all of this tech all of this invention is compounding on top of each other Exactly. As a result. Right? And back in the old days, if you look at the way, Moore’s Law was working, the software was static. Right. It was pre it was pre compiled as shrink wrapped, put into a store. It was was static. And the hardware underneath was growing at Moore’s Law rate. Right. Now we’ve got the whole stack growing. Right? Innovating across the whole stack. And so I think that that’s the now now all of a sudden, we’re seeing scaling, that is that is extraordinary, of course. But but, we used to talk about pre trained models and scaling at that level and how we’re doubling the model size and doubling, therefore, appropriately doubling the data size. And as a result, the computing capacity necessary is, increasing by a factor of 4 every year. Right. That was a big deal. Right. But now we’re seeing scaling with post training, and we’re seeing scaling at inference. Isn’t that right? And so people used to think that pre training was was hard and inference was easy. Now everything is hard Right. Right. Which is kind of sensible. You know, the idea that that all of all of human thinking is is one shot is kind of ridiculous. And so there’s there must be a concept of fast thinking and slow thinking and and reasoning and reflection and iteration and simulation and all that, and that now it’s coming in. Yeah. I think to that point, you know, one of the most misunderstood things about NVIDIA is how deep the true NVIDIA moat is. Right? I think there’s a notion out there that, you know, if some as soon as someone invents a new chip, a Yeah. A better chip, that, you know, that they’ve won. But the truth is you’ve been spending the past decade building the full stack from the GPU to the CPU to the networking and especially the software and libraries that enable applications Yeah. To run on NVIDIA. Yeah. So I think you spoke, you know, to that. But, you know, when you think about NVIDIA’s moat today Yeah. Right, do you think NVIDIA’s moat today is greater or or or smaller than it was 3 to 4 years ago? Well, I I appreciate you you recognizing how computing has changed. In fact, the reason why people thought, and many still do, that you designed a better chip, it has more flops, has more flips and flops and bits and bytes. You know what I’m saying? Yeah. And and you you see that you see their keynote slides, and it’s got all these flips and flops and, you know, bar charts and things like that. And and that’s all good. I mean, look, horsepower does matter. Yes. So these things fundamentally do matter. However however, unfortunately that’s old thinking. It is old thinking in the sense that the software was was, some application running on Windows and the software is static. Right. Which means that the best way for you to improve the system is just making faster and faster chips. But we realized that machine learning is not human programming. Machine learning is not about just the software, it’s about the entire data pipeline. It’s about, in fact, the flywheel of machine learning is the most important thing. So how do you think about enabling this flywheel on the one hand, and enabling data scientists and researchers to be productive in this flywheel? And that flywheel is is, starts at the very, very beginning. A a lot of people don’t even realize that it takes AI to curate data to teach an AI. And that AI alone is pretty complicated. Yeah. And as that AI itself is improving, is it also accelerating, you know, again, when we think about the competitive advantage Yeah. Right? It’s combinatorial of all these systems. Exactly. Exactly. And and that was exactly gonna lead to that because of smarter AIs to curate the data. Right. We now even have synthetic data generation and all kinds of different ways of of curating data, presenting data to and so before you even get the training, you’ve got massive amounts of data processing involved. And so so people think about, oh, PyTorch, that’s the beginning end of the world, and it it was very important. But don’t forget, before PyTorch is a month amount of work. After PyTorch is a month of work. And and that to think about the flywheel is really the way you ought to think. You know, how do I think about this entire flywheel and how do I design a computing system, a computing architecture that helps you take this flywheel and be as effective as possible? It’s not one size slice of an application, Training. Does that make sense? That’s just one step. Yep. Okay? Every step along that flywheel is hard. And so the first thing that you should do, instead of thinking about, how do I make Excel faster? How do I make, you know, doom faster? That was kind of the old days. Isn’t that right? Now you have to think about how do I make this flywheel faster? And this flywheel has a whole bunch of different steps. There’s nothing easy about machine learning as you guys know. There’s nothing easy about what OpenAI does or X does or Gemini and the team that DeepMind does. I mean, there’s nothing easy about what they do. And so we decided, look, this is really what you ought to be thinking about. This is the entire process. You want you want to accelerate every part of that. You wanna respect Amdahl’s law. You wanna Amdahl’s law would suggest, well, if this is 30% of the time and I accelerated that by a factor of 3, I didn’t really accelerate the entire process by that much. Mhmm. Does that make sense? Right. And it you really wanna create a system that accelerates every single step of that because only in doing the whole thing can you really materially improve that cycle time. And that flywheel that’s that that that that rate of learning is really, in the end, what causes the exponential rise. And so our what I’m trying to say is that our perspective about you know, a company’s perspective about what you’re really doing manifests itself into the product. Right. And notice, I’ve been talking about this flywheel, you know The entire site. Yeah. That’s right. Yeah. And we accelerate everything. Right. Right now right now, the main focus is video. A a lot of people are focused on on on physical AI and video processing. Right. Just imagine that front end. Right. The the terabytes per second of data that are coming into the system. Mhmm. Give me an example of a pipeline that is gonna ingest all of that data Right. Prepared for training in the first place. Yeah. So that entire thing is CUDA accelerated. Yeah. And people are only thinking about text models today. Yeah. But the future is, you know, this video models as well as, you know, using, you know, some of these text model like o one to really process a lot of that data before we even get there. Yeah. Right? Yeah. Yeah. So language models are gonna be involved in every single Yeah. It took us took the industry enormous technology and effort to train a language model, to train these large language models. Now we’re using a large language model in every single step of the way. It’s pretty pretty phenomenal. I don’t mean to be overly simplistic about this, but again, you know, we hear it all the time from investors. Right? Yes, but. What about custom ASICs? Yes, but Yeah. Their competitive mode is going to be pierced by this. What I hear you saying is that in a combinatorial system Yeah. The advantage grows over time. So I heard you say that our advantage is greater today than it was 3 to 4 years ago because we’re improving every component and that’s combinatorial. Is that, you know, when you think about, for example, as a business case study, Intel. Right? Who had a dominant mode, a dominant position in the stack relative to where you are today. Perhaps just, you know, again, boil it down a little bit. You know, compare contrast your competitive advantage to maybe the competitive advantage they had at the peak of their cycle. Well, Intel is extraordinary. Intel is extraordinary because they were probably the first company that was, incredibly good at manufacturing, process engineering manufacturing, and that one click above manufacturing which is building the chip. Right. And designing the chip and architecting the chip in the x86 architecture, and building faster and faster x86 chips, that was their brilliance and they they fused that with manufacturing. Our company is a little different in the sense that we recognize this that that in fact, parallel processing doesn’t require every transistor to be excellent. Serial processing requires every transistor to be excellent. Parallel processing requires lots and lots of transistors to be more cost effective. I’d rather have 10 times more transistors, 20% slower Right. Than 10 times less transistor, 20% faster. Does that make sense? They would like the opposite. Mhmm. And so single threaded performance, single threaded processing, and parallel processing was very different. And so we we observed that, in fact, our world is not about being better going down. We wanna be very good as as good as we can be. But it’s our world is really about much better going up. Mhmm. Parallel computing, parallel processing is hard because, every single algorithm requires a different way of refactoring and re architecting the algorithm for the architecture. Right. What people don’t realize is that you can have, 3 different ISAs, CPU ISAs. They all have their own c compilers. You could take you could take software and compile down to that ISA. That’s not possible in accelerated computing. That’s not possible in parallel computing. The company who comes up with the architecture has to come up with their own Open GL. Right. So we revolutionized deep learning because of our domain specific library called cuDNN. Without cuDNN, nobody talks about cuDNN because it’s one layer underneath PyTorch and, you know, and and TensorFlow. And back in the old days, Caffe and Theano and and now Triton. And there’s a whole bunch of different different frameworks. And so that domain specific lang library, cuDNN, a domain specific library called OPTIX. We have a domain specific library called cuQuantum, RAPIDS, the the list of, you know, aerial for for, for Industry specific algorithms that sit below, you know, that PyTorch layer that everybody’s focused on. Like I’ve heard oftentimes, well, you know, if LLMs If I didn’t if we didn’t invent that, no application on top could work. Right. Do you guys understand what I’m saying? So the mathematics is real what NVIDIA is really good at is algorithm. Right. That in the fusion between the the science above the architecture on the bottom, that’s what we’re really good at. Right. Yeah. There’s all this attention now on inference Yeah. Finally. But I remember, you know, 2 2 years ago, Brad and I had dinner with you and we asked you the question, you know, do do you think your moat will be as strong in inference as it is in training? Yeah. And And I’m sure I said it would be it would be greater. Yeah. Yeah. And and and you touched upon a lot of these elements just now just, you know, the composability between or, you know, the we don’t know the total mix at one point into a customer. It’s very important to be able to be flexible in between. That’s right. But can you just touch upon, you know, now that we’re in this era of inference? Yeah. It was, you know, inference training is inferencing at at scale. I mean, you’re right? Correct. Mhmm. And so so, if you if you if you train well, it is very likely you’ll inference well. Mhmm. If you built it on this architecture without any consideration, it will run on this architecture. Okay? You could you could still go and optimize it for other architectures, but at the very minimum, since it’s already been architected, you know, built on NVIDIA, it will run on NVIDIA. Now the other aspect, of course, is just kind of, you know, capital investment aspect, which is when you’re training new models, you want your best new gear to be used for training Right. Which leaves behind gear that you used yesterday. Well, that gear is perfect for inference. Mhmm. And so there’s there’s a there’s a trail of free gear. Mhmm. There’s a trail of free infrastructure behind the new infrastructure that’s CUDA compatible. Mhmm. And so we we’re we’re very disciplined about making sure that we’re compatible throughout so that everything that we leave behind will continue to be excellent. Now we also put a lot of energy into continuously reinventing new algorithms so that when the time comes, the hopper architecture is 2, 3, 4 times better than when they bought it. Mhmm. So that that you’ll that infrastructure continues to be really effective. Mhmm. And so all of the work that we do, improving new algorithms, new frameworks, notice it helps every every single installed base that we have. Hopper is better for it. Ampere is better for it. Even Volta is better for it. Yeah. Okay? And and I think Sam was just telling me that that they had just, decommissioned the the Volta infrastructure that they have at OpenAI recently. And so so I I think it’s, we we leave behind this trail of install base. Just like all computing, install base matters. And NVIDIA is in in every single cloud where, you know, on prem and and and at all the way out to the edge. And so the the the Vela, you know, vision language model that been created in the cloud works perfectly at the edge on a robot Mhmm. Without modification. It’s all CUDA compatible. And so so I think this this idea of architecture compatibility was important for large it’s no different for iPhones and no different for anything else. I think the installed base is really important for inference. But the thing that that I really really, we really benefit from is because we’re we’re working on training these large language models and the new architectures of it, we’re we’re we’re able to think about how do we create architectures that’s excellent at inference someday when the time comes. And so we’ve been thinking about about, iterative models for for reasoning models and how do we create very, interactive inference experiences for this Right. Personal agent of yours. Right. You don’t wanna say something and have to go off and think about it for a while. You want it to interact with you quite quickly. So how do we create such a thing? And what came out of it was NVLink. Right. You know, NVLink so that we could take, these systems that are excellent for training, but when you’re done with it, the the inference performance is ex exceptional. Mhmm. And so you wanna you wanna optimize for this time to first token. Right. And time to first token is is, insanely hard to do actually because time to first token requires a lot of bandwidth. But if your context is also rich, then, you need a lot of flops. Yeah. And so you need a infinite amount of bandwidth, infinite amount of flops at the same time in order to achieve just a few millisecond response time. And so that that architecture is really hard to do and we invented, Grace Blackwell NVLink for that. Right. In the spirit of time, I have more questions about that but but Well, don’t worry don’t worry about the time. Hey, guys. Hey, hey, hey, listen. Janine? Yeah. Look. Let’s do it till right. Let’s do it until right. There you go. I love it. I love it. So you you know, I was at dinner Yeah. With Andy Jassy earlier. See now we don’t have to worry about the time. Earlier with Andy Jassy earlier this week. And Andy said, you know, we’ve got Trainium, you know, coming and Infrencia coming, and I think most people, again, view these as a problem for NVIDIA. But in the very next breath, he said NVIDIA is a huge and important partner to us and will remain a huge and important partner for us as far as I can see into the future. The world runs on NVIDIA. Right? So when you think about the custom ASICs that are being built, that are going to go after targeted application, Maybe the inference accelerator at meta, maybe, you know, trainium at Amazon, you know, or Google’s TPUs. And then you think about the supply shortage that you have today. Do any of those things change that dynamic? Right? Or are they complements to the systems that they’re all buying from you? We’re just doing different things. Yes. We’re we’re trying to accomplish different things. And what NVIDIA is trying to do is build a computing platform for this new world, this machine learning world, this generative AI world, this agentic AI world. We’re trying to we’re trying to create, you know, as you know, in the what what’s just so deeply profound is after 60 years of computing, we reinvented the entire computing stack. The way you write software from programming to machine learning, the way that you process software from CPUs to GPU, the way that the way that, the the applications from software to artificial intelligence. Right? And so, software tools to artificial intelligence. So so every aspect of the computing stack and the technology stack has been changed. You know, what we would like to do is to to create a computing platform that’s available everywhere. And this is really the the the complexity of what we do. The complexity of what we do is if you think about what we do, we we’re building an entire AI infrastructure and we think of it as one computer. Right. I’ve said before, the data center is now the unit of computing. Yeah. Yeah. To me, when I think about a computer, I’m not thinking about that chip. Right. I’m thinking about this thing. That’s my mental model. And all the software and all the orchestration, all the machinery that’s inside, that’s my that’s my computer. And we’re trying to build a new one every year. Yes. That’s insane. Insane. Nobody has ever done that before. We’re trying to build a brand new one every single year. And every single year, we deliver 2 or 3 times more performance. Mhmm. As a result, every single year, we reduce the cost by 2 or 3 times. Every single year, we improve the energy efficiency by 2 or 3 times. Right. Right? And so we ask our customers, don’t buy everything at one time. Buy a little every year. Right. Okay. And the reason for that, we want them cost averaged into the future. All of it’s architecturally compatible. Okay? Now so that building that alone at the pace that we’re doing is incredibly hard. Now the double part, the double hard part, is then we take that all of that, and instead of selling it as an infrastructure or selling it as a service, we disaggregate all of it and we integrate it into GCP. We integrate it into AWS. We integrate it into Azure. We integrate it into X. We integrate does that make sense? Yes. And so everybody’s integration is different. We gotta get we have to get all of our architectural libraries and all of our algorithms and all of our frameworks and integrate it into theirs. We get our security system integrated into theirs. We get our networking integrated into theirs. Isn’t that right? Right. Then we do basically 10 integrations. Mhmm. And we do this every single year. Right. Now, that is the miracle. That is the miracle. Why were you I mean, it’s it’s madness. It’s madness that you’re trying to do this every year. That’s what I’m thinking about. So so so what drove you to do it every year and then related to that, you know Clark’s just back from Taipei and Korea and Japan when meeting with all your supply partners Yeah. Who you have decade long relationships with. Yeah. How important are are those relationships Yeah. To again the combinatorial math that builds that competitive moat? Yeah. That’s that’s, when you when you break it down systematically, the more you guys break it down, the more everybody breaks it down, the more amazed that they are. Yes. And and, how is it possible that the entire, ecosystem of electronics today is dedicated in working with us to build ultimately this cube of a computer integrated into all of these different ecosystems, and the coordination is so seamless. So there’s obviously APIs and and methodologies and business processes and design rules that we’ve propagated backwards and methodologies and architectures and a APIs that we’ve propagated forward. That have been hardened for decades. Hardened for decades. Yeah. And also evolving as we go. And, but they they these APIs have to come together. Right. Right. When the time comes, all these things in Taiwan, you know, all over the world being manufactured, they’re gonna land somewhere in in Azure’s data center. They’re gonna come together and click, click, click, click, click. Someone just calls an, OpenAI API and it just works. That’s right. Yeah. Exactly. Yeah. There’s a whole bunch of craziness. Right? It’s a whole chain. And so that’s what we invented. That’s what we invented. This this massive infrastructure of computing. Yeah. The whole planet is working with us on it. It’s integrated into everywhere. It’s you could sell it through Dell. You could sell it through HPE. It’s hosted in the cloud. It’s in, it’s all the way out at the edge. People use it in robotic systems now, robot and, you know, human robots. They’re in self driving cars. They’re all architecturally compatible. Pretty kinda craziness. You know? It’s it’s craziness. Clark, I don’t wanna I don’t want you to leave the impression I didn’t answer the question. In fact, I did. What I meant by that when, relating to your ASEC is is, the the way to think about we’re just doing something different. Yes. As a company as a company, we wanna be situationally aware and I’m very situationally aware of everything around our company and our ecosystem. Right. I’m aware of all the people doing alternative things and and what they’re doing and and and sometimes sometimes it’s adversarial to us, sometimes it’s not. I’m super aware of it. Mhmm. But that doesn’t change what the purpose of the company is. Yeah. The singular purpose of the company is to build an architecture Mhmm. That a platform that could be everywhere. Right. That is our goal. Mhmm. We’re not trying to take any share from anybody. NVIDIA is a market maker, not share taker. If you look at our company slides, we don’t we don’t show not one day does this company talk about market share, not inside. All we’re talking about is how do we create the next thing, what’s the next problem we can solve in that flywheel, how can we do a better job for people? Mhmm. How do we take that that flywheel that used to take about a year? How do we crank crank it down to about a month? Yes. You know? What’s the speed of light of that? Isn’t that right? And so we’re thinking about all these different things, but the one thing we’re not we’re not too we’re situationally aware of everything, but we’re certain that the what our mission is is very singular. The only question is whether that mission is necessary. Does that make sense? Yes. You know, and all companies, all great companies, ought to have that at its core. It’s about what are you doing? For The only question, is it necessary? Is it valuable? Right. Is it impactful? Does it help people? And and I am certain that you’re a developer, you’re you’re a generative AI start up and and you’re about to decide how to become a company. The one choice that you don’t have to make is which one of the a six do I support? If you just support Acuda, you know you could go everywhere. You could always change your mind later. Right. But we’re the on ramp to the world of AI. Isn’t that right? Once you decide to come onto our platform, the other decisions you could defer. You could always build your own ASIC later. Right. You know, we’re not against that. We’re not offended by any of that. When I work with when we work with, all the GCPs, the GCPs, Azure, we present our roadmap to them years in advance. They don’t present their ASIC roadmap to us, and it doesn’t ever offend us. Mhmm. Does that make sense? We we create we’re in a if you have a sole purpose and your purpose is meaningful and your mission is is is dear to you and is dear to to everybody else, then you could be transparent. Notice my road map is transparent on GTC. My road map goes way deeper to our friends at Azure and AWS and others. We have no trouble doing any of that even as they’re building their own ASIC. I think, you know, when when people observe the business you said recently that the demand for Blackwell is insane. You said one of the hardest parts of your job is the emotional toll of saying no to people in a world that, has a shortage of the compute that you that you can produce and have on offer. But critics say this is just a moment in time. Right? They they say this is just like Cisco in 2000, we’re overbuilding fiber, it’s gonna be boom and bust. You know, I I think about the start of 23 when we were having dinner. The forecast for NVIDIA at that dinner in January of 23 was that you would do 26,000,000,000 of revenue, for the year 2023. You did 60,000,000,000. Right? The the 25 people Let’s just let let let the truth be known. That is the single greatest failure of forecasting the world has ever seen. Right. Right. Right. Can we all can we all at least admit that? What what what what to me to me That was my takeaway. I just got And that was and that was we got so excited in November 22 because we had folks like Mustafa from Inflexion and Noah from character coming in our office talking about investing in their companies. And they said, well, if you can’t pencil out investing in our companies, then buy NVIDIA because everybody in the world is trying to get NVIDIA chips to build these applications that are gonna change the world. And of course, the Cambrian moment occurred with chat gpt and notwithstanding that fact, these 25 analysts were so focused on the crypto winner that they couldn’t get their head around an imagination of what was what was happening in the world. Okay? So it ended up being way bigger. You say, in very plain English, the demand is insane for Blackwell, that it’s going to be that way for as far as you can, you know, for as far as you can see. Of course, the future is unknown and unknowable, but why are the critics so wrong that it that this isn’t going to be the Cisco like situation of overbuilding in the in in in 2000? Yeah. The best way to to think about the future is reason reason about it from first principles. Correct. Okay. So so the the question is what are the first principles of what we’re doing? Number 1, what are we doing? What are we doing? The first thing that we are doing is we’re reinventing computing, do we not? We just said that. The way that computing will be done in the future will be highly machine learned. Yes. Highly machine learned. Okay. Almost everything that we do, almost every single application, Word, Excel, PowerPoint, Photoshop, Premiere, you you you know, AutoCAD. You you give me your favorite application that was all hand hand engineered. I promise you it will be highly machine learned in the future. Isn’t that right? And so all these tools will be and and on top of that, you’re gonna have machines, agents that you help you use them. Right. Okay? And so we know this for a fact at this point. Right. Right? Isn’t that right? We’ve reinvented computing. We’re not going back. The entire computing technology stack is being reinvented. Okay. So now that we’ve done that, we said that software is gonna be different. What software can write is gonna be different. How we use software will be different. So let’s let’s now acknowledge that. So those are my ground truth now. Yes. Now the question therefore is, what happens? And so let’s go back and let’s just take a look at how’s computing done in the past. So we have a $1,000,000,000,000 worth of computers in the past. We look at it. Just open the door, look at the data center, and you look at it and say, are those the computers you want doing that? Doing that future? And the answer is no. Right. Right? You got all these CPUs back there. We know that what what it can do and what it can’t do. And we just know that we have a $1,000,000,000,000 worth of data centers that we have to modernize. And so, right now, as we speak, if we were to to have a trajectory over the next 4 or 5 years to modernize that old stuff, that’s not unreasonable. Right. Sensible. So we have a And you’re having those conversations with the people who have to modernize it. Yeah. So it’s And they’re modernizing it on GPU. That’s right. I mean, right well, let’s let’s make another test. You have you have you have, $50,000,000,000 of CapEx you’d like to spend. Option a, option b. Build CapEx for the future Right. Or build CapEx like the past. Right. Now, you already have the CapEx of the past. Right. Right. It’s sitting right there. It’s not getting much better anyways. Moore’s Law has largely ended. And so why rebuild that? Let’s just take $50,000,000,000 put it into generative AI. Isn’t that right? And so now your company just got better. Right. Now how much of that 50,000,000,000 would you put in? Well, I would put in a 100% of the 50,000,000,000 because I’ve already got 4 years of infrastructure behind me. That’s the of the of the past. Mhmm. And so now now you just I just reasoned about it, from the perspective of somebody thinking about it from first principles. And that’s what they’re doing. Smart people are doing smart things. Now the second part is this. So so now we have a $1,000,000,000,000 worth of capacity to go build. Right? $1,000,000,000,000 worth of infrastructure. What about, you you know, call it a $150,000,000,000 into it. Right. Okay? So we have we have a $1,000,000,000,000 in infrastructure infrastructure to go build over the next 4 or 5 years. Well, the second thing that we observe is that the way that software is written is different, but how software is gonna be used is different. In the future, we’re gonna have agents. Isn’t that right? Correct. We’re gonna have digital employees in our company. Mhmm. In your inbox, you have all these little dots and these little faces. In the future, there’s gonna be little icons of AIs. Isn’t that right? I’m gonna be sending them I’m gonna be I’m no longer gonna program computers with c plus plus. I’m gonna program AIs with prompting. Isn’t that right? Now this is no different than me talking to my you know this morning, I I wrote a bunch of emails before I came here. I was prompting my team. Of course. Right? Yeah. And I I would describe the context. I would describe the the the fundamental constraints that I I know of, and I would describe the mission for them. I would leave it sufficiently, I would be sufficiently directional so that they understand what I need, and I wanna be clear about what the outcome should be as clear as I can be. But I leave enough ambiguous space on you know, a lit a creativity space so they can surprise me. Isn’t that right? Absolutely. There’s no different than how I prompt an AI today. Yeah. It’s exactly how I prompt an AI. And so what’s gonna happen is is on top of this infrastructure of IT that we’re gonna modernize, there’s gonna be a new infrastructure. This new infrastructure are going to be AI factories that operate these digital humans. Right. And they’re gonna be running all the time, 247. Mhmm. Right. We’re gonna have them for all of our companies all over the world. We’re gonna have them in factories. We’re gonna have them in autonomous systems. Isn’t that right? So there’s a whole layer of computing fabric, a whole layer of what I call AI factories that the world has to make that doesn’t exist today at all. Right. So the question is how big is that? Right. Unknowable at the moment. Probably a few $1,000,000,000,000. Right. Unknowable at the moment. But as we’re sitting here building into the beautiful thing is the architecture for this modernizing this new data center and the architecture for the AI factory is the same. Mhmm. Right. That’s the nice thing. And you you made you made this clear. You’ve got a trillion of old stuff you gotta modernize. You at least have a trillion of new AI workloads coming on. Yeah. You’re give or take, you’ll do a 125,000,000,000 in revenue this year. You know, there was at one point somebody told you the company would never be worth more than a 1000000000. As you sit here today, is there any reason, right, if you’re only a 125,000,000,000 out of a multitrillion, Tam, that you’re not going to have 2 x the revenue, 3 x the revenue in the future that you have today? Is there any reason your revenue doesn’t? No. Yeah. Yeah. The as as you know, the it’s not about it’s not about everything is you know, companies companies are only limited by the size of the the fish pond. You know? Yes. A goldfishing can only be so big. And so the question is, what is our what is our fish pond? What is our pond? And that requires a little imagination. And this is the reason why market makers think about that future without creating that new fish pond. It’s hard it’s hard to to figure this out looking backwards and try to take share. Right. You know, share takers can only be so big. For sure. Market makers can be quite large. For sure. Yeah. For sure. And so, you know, I I think I think the the good fortune that our company has has is that since the very beginning of our company, we had to invent the market for us to go swim it. Yeah. That market and people don’t realize this back then, but anymore. But, you know, we were at the at the at ground 0 of creating the 3 d gaming PC market. Right. Right. We we largely invented this market And all the ecosystem and all the the graphics card ecosystem, we invented all that. And and so so the the the the need to invent a new market to go serve it later is something that’s very comfortable for us. Exactly. Exactly. And speaking to somebody who’s invented a new market, you know, let’s shift gears a little bit to models and OpenAI. OpenAI raised, as you know, 6 and a half $1,000,000,000, this week. Yeah. At like a $150,000,000,000 valuation. We both participated. Yeah, we’re really happy for them, really really happy they came together. Right. Yeah, they did a great stand and the team did a great job. The show. Reports are that they’ll do 5,000,000,000 ish of revenue or run rate revenue this year maybe going to 10,000,000,000 next year. If you look at the business today it’s about twice the revenue as Google was at the time of its IPO. They have 250,000,000 Is that right? Yeah 250,000,000 weekly average users which we estimate is twice the amount Google had at the time of its IPO. Wow. And if you look at the multiple of the business, if you believe 10,000,000,000 next year, it’s about 15 times the forward revenue, which is about the multiple of Google and Meta at the time of their IPO. Wow. Right? When you think about a company that had 0 revenue, 0 weekly average users 22 months ago. Brad has an incredible command of history. When you think about that, talk to us about the importance of OpenAI as a partner to you and OpenAI as a force in kind of driving forward, you know, kind of public awareness and usage around AI. Well, this this is one of the one of the most consequential companies of our time. The, a pure play AI company pursuing the vision of AGI. Right. And whatever its definition. Right. I almost don’t think it matters fully what the definition is nor do I you know, really believe that the timing matters. Right. The one thing that I know is that that AI’s AI’s gonna have a road map of capabilities over time and that road map of capabilities over time is gonna be quite spectacular. Mhmm. And, along the way, long before it even gets to anybody’s definition of AGI, we’re gonna put it to great use. Right. All you have to do is, right now as we speak, go go talk to, digital biologists, climate tech researchers, material researchers, physical sciences, astrophysicists, quantum chemists. You go ask video game designers, manufacturing, engineers, roboticists. Pick your favorite Right. Whatever industry you wanna go pick. Right. And you go deep in there and you talk to the people that matter and you ask them, has AI revolutionized the way you work? Right. And you take those data points and you come back and you you then get to ask yourself, how skeptical do you wanna be? Right. Right. Because they’re not talking about AI as a conceptual benefit someday. They’re talking about using AI right now. Correct. Right now. Ag tech, material tech, climate tech, you you pick your tech. You pick your field of science. They are advancing. AI is helping them advancing their work right now as we speak. Every single industry, every single company, every high every university. Unbelievable. Isn’t that right? Right. It is absolutely, going to somehow transform business. We know that. Right. We I mean, we we it’s it’s so tangible you could It’s happening today. It’s happening today. It’s happening today. Yeah. And and and so I think I think, I think that the awakening of AI, chat gpt triggered is completely incredible and I love their, their velocity and their their singular purpose of advancing this field and and so really really consequential. And they build an economic engine that can finance the next, you know, frontier of models. Right? And I think there’s a growing consensus in Silicon Valley that the whole model layer is commoditizing. Llama is is is is making it very cheap for lots of people to build models and so early on here we had a lot of model companies. You know, character and inflection and and Cohere and Mistral and go through the list. And a lot of people question whether or not those companies can build the escape velocity on the economic engine that can continue funding those next generation. My own sense is that there’s gonna be that’s why you’re seeing the consolidation. Right? It’s OpenAI clearly has hit that escape velocity. They can fund their own future. It’s not clear to me that many of these other companies can. Is that a fair kind of review of the state of things in the model layer that we’re going to have this consolidation like we have in lots of other markets to market leaders who can afford, who have an economic engine or an application that allows them to continue to invest? There’s a first of all, there’s a different fundamental difference between a model Yes. And artificial intelligence. Yes. Right? Yeah. A model is an essential ingredient Correct. For artificial intelligence. It’s necessary but not sufficient. Correct. And so and the and artificial intelligence is a capability, but for what? Right. Then what’s the application? Right. The artificial intelligence for self driving cars is related to the artificial intelligence for human robots, but it’s not the same. Mhmm. Which is related to the artificial intelligence for a chatbot, but not the same. Correct. And so so you you have to understand the taxonomy Yes. Of Stack. Yeah. Of the stack. Yeah. And at every layer of the stack, there will be opportunities, but not infinite opportunities for everybody at every single layer of the stack. Right. Now I just said something. All you have to do is replace the word, model with GPU. In fact, this was the great observation of our company 32 years ago, that there’s a fundamental difference between GPU, graphics chip or GPU, versus accelerated computing. And accelerated computing is a different thing than the work that we do with AI infrastructure. It’s related, but it’s not exactly the same. It’s built on top of each other. It’s not exactly the same. And each one of these layers of abstraction requires fundamental different skills. Somebody who’s really, really good at building GPUs have no clue how to be an accelerated computing company. I can I you know, there are a whole lot of people who build GPUs? Yeah. And I don’t know which one it came some came you know, we invented the GPU, but you know that we’re not we’re we’re not the only company that makes GPUs today. Correct. You know? And so there are GPUs everywhere. And but they’re not accelerated computing companies. And and there are a lot of people who you know, there’s they’re they’re accelerators accelerators that does, application acceleration. But that’s different than an accelerated computing company. And so, for example, a very specialized AI application Right. Could that could be a very successful thing. Correct. That is MTIA. That’s right. Right. But it might not be the type of company that that, had broad reach and broad capabilities. And so so you’ve gotta you’ve gotta decide where you wanna be. There’s opportunities probably in all these different areas, but, like, building companies. You have to be mindful of the the the shifting of the ecosystem and what gets commoditized over time, recognizing what’s a feature versus a product Right. Versus a company. For sure. Okay? I just I just went through okay. There’s a lot of different ways you can think about this. Of course there’s one new entrant that has the money, the smarts, the ambition, that’s x.ai. Yeah. Right? And, well there are reports out there that that you and Larry and Elon had dinner. They talked to you out of a 100000 h one hundreds. They went to Memphis and built a large coherent super cluster in in a matter of months. You know So first, 3 three points don’t make a line. Okay. Yes, I had dinner with them. Causality is it. What do you think about their ability to stand up that super cluster and there’s talk out there that they want another 100000 h two hundreds, right, to expand the size of that super cluster. You know, first talk to us a little bit about x and their ambitions and what they’ve achieved, but also are we already at the age of clusters of 203100000 GPUs? The answer is yes. And then the, first first of all, acknowledgement of of achievement where it’s deserved. From the moment of concept to, a data center that’s ready for NVIDIA to have our gear gear there to the moment that we, powered it on, had it all hooked up, and it did its first training. Yeah. Okay? Correct. So, that first part, just building a massive factory, liquid cooled, energized, permitted, in the short time that was done, I mean, that is that is, like, superhuman. Right. Yeah. There’s and and as far as as far as I know, there’s only one person in the world who could do that. You know? I mean, Elon is singular in this understanding of engineering and and construction and large systems and, and and and marshaling resources. Incredible. Yeah. Just it it’s unbelievable. And and then and, of course, then his engineering team is extraordinary. I mean, the the software team is great. The networking team is great. The infrastructure team is great. You know, Elon understands this deeply. And from the moment that we decided to get to go, the planning of with our engineering team, our networking team, our our infrastructure and computing team, the software team, all of the preparation in advance, then all of the infrastructure, all of the logistics and the amount of technology and equipment that came in on that day, NVIDIA NVIDIA’s infrastructure and and computing infrastructure and all that technology, to training 19 days. Hang on. Just you you know what? You don’t want that Did anybody sleep 247? No no question that nobody slept. But but first of all, some 19 days is incredible. Mhmm. But it’s also kinda nice to just take a step back and just, do you know how 19 how many days 19 days is? It’s just a couple of weeks. Yeah. Right. And and the mountain of technology, if you were to see it, is unbelievable. All of the wiring and the networking and, you know, networking NVIDIA gear is very different than networking hyperscale data centers. Okay? The number of wires that goes in one node, the back of a computer is all wires. Just getting this mountain of technology integrated and all the software, incredible. Right. Yeah. So so I I think I think what Elon and the x team did and, and I I I’m really appreciative that he he acknowledges the the the engineering work that we did with him and and the planning work and all that stuff. But but what they achieved is is singular, Never been done before. Just to put in perspective, 100,000 GPUs, that’s, you know, easily the fastest supercomputer on the planet as one cluster. A supercomputer that you would build would take normally 3 years to plan. Right. And then they deliver the equipment, and it takes 1 year to get it all working. Yes. We’re talking about 19 days. Wow. Well, it’s the credit of the NVIDIA platform. Right? That it’s the whole processes are hardened. That’s right. Yeah. Yeah. Everything’s already working and Yeah. And, of course, there’s a whole bunch of, you know, x algorithms and x framework and x stack and things like that. And we said, we got a ton of integration we have to do, but the planning of it was extraordinary. Just preplanning of it to, you know n of 1 is right. Elon is an n of 1. Yeah. But you answered that question by starting off saying yes, 200 to 300000 GPU clusters are are are here. Yeah. Right? Does that scale to 500,000? Does it scale to a million? And does the demand for your products depend on it scaling to 1,000,000? That part the last part is no. My sense is that, distributed training will have to work. Right. And my sense is that distributed computing will be invented. Right. And and some form of federated learning and distributed, asynchronous distributed computing, is going to is going to, be discovered. And I’m very very enthusiastic and very optimistic about that. The the, of course of course, the, the thing to realize is that the scaling law used to be about pre training. Now we’ve gone to multi modality, we’ve gone to synthetic data generation. Post training has now scaled up incredibly. Mhmm. Synthetic data generation, reward systems, reinforcement learning based. Mhmm. And then now inference scaling Right. Has gone through the roof. Right. The idea that that a model, before it answers your answer, had already done internal inference Incredible. 10000 times Mhmm. Is probably not unreasonable. Mhmm. And it’s probably done tree search, it’s probably done reinforcement learning on that, it’s probably, you know, it’s probably done some simulations, surely done a lot of reflection. It probably looked up some data, looked up some information. Isn’t that right? Mhmm. And so its context is probably fairly large. I mean, this this type of intelligence is well, that’s what we do. Right. That’s what we do. Isn’t that right? And so so the ability this this scaling, if you just did that math, and you compound it with you you compound that with 4 x per year on model size and computing size. And then on the other hand, demand continues to grow in usage. Do we think that we need millions of GPUs? No doubt. Yeah. Yeah. That is that is a first certainty now. Yeah. And so the question is how do we architect it from a data center perspective? And that has has a lot to do with, you know, are are there data centers that are gigawatts at a time or are they 250 megawatts at a time and and, my sense is that, you know, you’re gonna get both. I think analysts always focus on the current architectural bet. But I think one of the biggest takeaways from this conversation is that we’re thinking about the entire ecosystem and many years out. Mhmm. So, you know, the idea that, you know, because NVIDIA is just scaling up or scaling out, it’s to meet the future. It’s not to, you know, not not such that, you know, you’re only dependent on a world where there’s a 500,000 or a 1000000, you know, GPU cluster, it’s, you know, by the time there’s distributed training, you’ll have written, you know, the software to enable that. That’s right. Remember Yeah. Without Megatron Yeah. That we developed With with some 7 years ago now Yeah. The scaling of these large training jobs wouldn’t have happened. Right. And so we invented Megatron, we invented Nickel, GPU direct. Right? All of the work that we did with our DMA, that made it possible for easily to do pipeline parallelism. You know? Right? Mhmm. And so, you know, all the all the model parallelism that’s being done, you know, all the breaking of the distributed training and all the batching and all the all of that stuff is is because we did the early work and now we’re doing the early work for the future future generation. So so let’s talk about strawberry and o one. Yeah. I wanna be respectful of your time. So I got all the time in the world. Actually, well, you’re you’re very generous. Yeah. I got all the time in the world. But first, I think it’s cool that they named o one after the o one visa. Right? Which is about recruiting the world’s best and brightest, you know, and bringing them to the United States. It’s something I know we’re both deeply passionate about. So I love the idea that building a model that thinks and that takes us to the next level of scaling intelligence Mhmm. Right, is is is an homage to the fact that it’s these people who come to the United States by way, of immigration that have made it made us what we are bring their collective intelligence to be Surely an alien intelligence. Certainly. Yeah. You know, it was spearheaded by our friend, Nolan Brown, of course he worked at Pluribus in Cicero when he was at META. How big a deal is inference time reasoning as a totally new vector of scaling intelligence separate and distinct from, right, just building larger models? It’s a huge deal. It’s a huge deal. I think the, a lot of intelligence can’t be done a priori. Right. You know? And a lot of computing, even a lot of computing can’t be reordered. I mean, just you know, out of order execution can’t be done a priori, you know. And so a lot of things can only be done in run time. Right. And and so so whether you think about it from a computer science perspective or you think about it from from a from a intelligence perspective, too much of it requires context, Right. The circumstance, right, the quality the type of answer you’re looking for. Sometimes just a quick answer is good enough. Depends on the consequential impact of the answer. You know, depending on the nature of the usage of that answer and so some answers, please take a night. Some answers, take a week. Yes. Is that right? So I could totally imagine me sending off a prompt to my AI and telling it, you know, think about it for a night. Right. Think about it overnight. Don’t tell me right away. Right. I want you to think about it all night. And then come back and tell me tomorrow what’s your best answer and reason about it for me. And and so I think the the, the the quality the the segmentation of intelligence from now from a product perspective Right. There’s gonna be one shot versions of it. Right. For sure. Yeah. And then there’ll be some that take 5 minutes, you know. And the intelligence layer that roots those questions to the right model Yeah. For the right use case. I mean, we were using advanced voice mode and o one preview last night. It I was I was coaching my son for his AP history test and it was like having the world’s best AP history teacher Yeah, right. Sitting right next to you thinking about these questions. It was truly extraordinary. Again My tutor is in AI today. Right. I’m blessed. Of course. They’re here today. Yeah. Which comes back to this, you know, over 40% of your revenue today is inference. But inference is about ready because of chain of reasoning. Yeah. Right? It’s about ready. Go up by a 1000000000 times. Right. By by by by a 1000000000x, by a by a 1000000000x. That’s right. That’s the part that most people have, you know, haven’t completely internalized. This is that industry we were talking about, but this is the industrial revolution. Right. That’s the production of intelligence. That’s right. Right? And Yeah. In It’s gonna go up a 1000000000 times. Right. And so, you know, everybody’s so hyper focused on NVIDIA as kind of, like, doing training on bigger models. Yeah. Right? Isn’t it the case that your revenue, if it’s 5050 today, you’re gonna do way more inference in the future. Yeah. Right? Then, I mean, training will always be important, but just the growth of inference is gonna be way larger than We hope. Growth in training. We hope. It’s almost impossible to conceive otherwise. Yeah. We hope. That’s right. That’s right. Right. I mean, it’s it’s good to it’s good to go to school. Yes. But the goal is so that you could be productive in society later. And so it’s good that we train these models, but the goal is to inference them, you know. Are you already using chain of reasoning and, you know, tools like o one in your own business to improve your own business? Yeah. Our cybersecurity system today can’t run without without, our own agents. Okay. We have we have agents help us design chips. Hopper wouldn’t be possible. Blackwall would be possible. Rubin, don’t even think about it. We have digital we have we have AI chip designers, AI software engineers, AI verification engineers, and we we build them all inside because, you know, we we, we have the ability and and we rather we rather use it use the opportunity to explore the technology ourselves. You know, when I walked into the building today, somebody came up to me and said, you know, ask Jensen about the culture, it’s all about the culture. I look at the business, you know, we talk a lot about fitness and efficiency, flat organizations that can execute quickly, smaller teams. Mhmm. You know, NVIDIA is in a league of its own really. You know, at about 4,000,000 of revenue per employee. About 2,000,000 of profits or free cash flow per employee. You build a culture of efficiency that really has unleashed creativity and innovation and ownership and responsibility. You’ve broken the mold on kind of functional management. Everybody likes to talk about all of all of your, direct reports. Is the leveraging of AI the thing that’s going to continue to allow you to be hyper creative while at the same time being efficient? No question. I’m hoping that that someday, NVIDIA has 32,000 employees today. Right. And, we have 4 we have 4,000 families in Israel. I hope they’re well. I’m thinking of you guys. Yes. Yes. And, I’m hoping that NVIDIA someday will be a 50,000 employee company with a 100,000,000, you know, AI assistants. Wow. And and they’re in every single group. Alright. We we’ll have a whole directory of, AIs that are just generally good at doing things. We’ll also have our inbox is gonna full of directories of AIs that we work with that we know are really, really good, specialized at our skill. And so so, AIs will recruit other AIs to solve problems. Right. AIs will be in, you know, Slack channels with each other. And with humans? Right. And with humans. And so so we’ll just be one large, you know, employee base, if you will. Some of them are digital and AI, some some of them are biological. And and I’m hoping some of them are even mechatronics. I I I think from a business perspective, it’s something that’s greatly misunderstood. You just described a company that’s producing the output of a company with a 150,000 people Mhmm. But you’re doing it with 50,000 people. That’s right. Now you didn’t say I was gonna get rid of all my employees. No. You’re still growing the number of employees in the organization, but the output of that organization, right, is gonna be dramatically more. This this is this is often misunderstood. AI is not it’s not AI will change every job. Right. AI will have a a a seismic impact on how people think about work. Let’s acknowledge that. Right. AI has the potential to do incredible good. It has the potential to do harm. We we we we have to build safe AI. Yes. We let’s just make that foundational. Yes. Okay? The part that is the part that is overlooked is when companies become more productive using artificial intelligence, it is likely that it manifests itself into either better earnings or better growth or both. Right. And when that happens, the next email from the CEO is likely not a layoff announcement. Of course. Because you’re growing. Yeah. And the reason for that is because we have more ideas than we can explore and we need people to help us think through it before we automate it. And so the automation part of it, AI can help us do. Obviously, it’s gonna help help us think through it as well, but it’s still gonna require us to go figure out what problems do I wanna solve. There are a trillion things we can go solve. What come what what problems does this company have to go solve? And select those ideas and figure out a way to automate and scale. And so so as a result, we’re gonna hire more people as we become more productive. People forget that. You know. And and and if you if you go back in time, obviously we have more ideas today than than 200 years ago, that’s the reason why GDPs are larger and more people are employed and even though we’re automating like crazy underneath. I I I it’s such an important point of this period that we’re entering. 1, almost all human productivity, almost all human prosperity is the byproduct of the automation Yeah. And the technology of the last 200 years. Yeah. I mean you can look at you know, from Adam Smith and Schumpeter’s creative, you know, destruction. You can look at chartered GDP growth per person over the course of last 200 years and it’s just accelerated. Yeah. Right. Which leads me to this question. If you look at the nineties, our productivity growth in the United States was about 2 and a half to 3 percent a year. Okay? And then in the 2000 it slowed down to about 1.8%. And then the last 10 years has been the slowest productivity growth. So that’s the amount of labor and capital or the amount of output we have for a fixed amount of labor and capital. The slowest we’ve had on record, actually. And a lot of people have debated the the reasoning for this, but if the world is as you just described and we’re going to leverage and manufacture intelligence, then isn’t it the case that we’re on the verge of a dramatic expansion in terms of human productivity? That’s our hope. Right. That’s our hope. And and of course, you know, we live in this world so we have direct evidence of it. Right. We have direct evidence of it, either, as isolated of a case as a individual researcher For sure. Who is able to, with AI, now explore science at such an extraordinary scale that is unimaginable, that’s productivity. Right. 100%. Measure productivity or that we’re designing chips that are so incredible at such a high pace and the chip complexities and the computer computer complexities we’re building are going up exponentially while the company’s employee base is not measure of productivity. Correct. The software that we’re developing better and better and better because we’re using AI and supercomputers to help us. The number of employees is growing barely linearly. Okay? Okay. Okay. Another demonstration of productivity. So whether it’s I can go into I can spot check it in a whole bunch of different industries. Yes. I could gut check it myself. Yes. If you’re in a business. That’s right. And so I I can, you know and and, of course, you can’t you can’t, we could be overfit, but the artistry of it, of course, is to to generalize what is it that we’re observing and whether this could manifest in other industries. And and there’s no question that, intelligence is the single most valuable commodity the world’s ever known Right. And now we’re gonna manufacture it at scale. And we we, all of us, have to get good at, you know, what would happen if you’re surrounded by these AIs, and they’re doing things so incredibly well and so much better than you. Right. And when I reflect on that, that’s my life. Right. I have 60 direct reports. Right. The reason why they’re on the reason why they’re on estaff is because they’re world class at what they do and they do it better than I do. Right. Much better than I do. Right. I have no trouble interacting with them. Mhmm. And I have no trouble prompt engineering them. Right. Totally. I have no trouble programming them. Right. Right. And so so I think that that’s that’s the thing that that people are going to learn is that they’re all gonna be CEOs. Right. They’re all gonna be CEOs of AI agents. Right. And their their ability to, have the creativity, the will, the the the the, and and some knowledge on how to reason, break problems down so that so that you can program these AI’s to help you achieve something like I do. Right. That’s called running companies. Right. Now it’s you mentioned something, this alignment, the safe AI. Mhmm. You mentioned the tragedy going on in the Middle East. You know, we have a lot of autonomy and a lot of AI that’s being used, in different parts of the world. So let’s talk for a second about bad actors, about safe AI, about coordination with Washington. How do you feel today? Are we on the right path? Do we have a sufficient level of coordination? You know, I think Mark Zuckerberg has said the way we beat the bad AIs is we make the good AIs better. Is, how would you characterize your view of how we make sure that this is a positive net bit benefit for humanity, as opposed to, you know, leaving us in this dystopian world without purpose? Mhmm. The conversation about safety is really important and good. Yes. The the abstracted view, this conceptual view of AI being a a large giant neural network, not so good. Right. Right. Okay. And the reason for that is because because, as we know, artificial intelligence and large language models are related, not the same. There there are many things that that are being done that I think are excellent. 1, open sourcing models so that, the entire community of researchers and every single industry and every single company can engage AI Yes. And go learn how to harness this capability for their application. Excellent. Number 2, the it is under celebrated the amount of technology that is dedicated to inventing AI to keep AI safe. Yes. AI is to carry data, to carry information, to train an AI. AI created to align AI, synthetic data generation AI to expand the knowledge of AI, to cause it to hallucinate less. All of the AIs that are being created to, to, for vectorization or graphing or whatever it is to to inform an AI, guard railing AI, AIs to monitor other AIs, that the system of AIs to create safe AI is under celebrated. Right. That we’ve already built. That we’re building everybody all over the industry. The methodologies, the red teaming, the process, the the the the model cards, the, you know, the evaluation systems, the benchmarking systems, you know, all of that, the the all of the harnesses that are that are being built at the velocity that’s been built is incredible. And what is the Under celebrated. Do you guys understand? Yes. You know, the the the world’s saying There’s no government regulation saying you have to do this. Yeah. This is the actors in the space today who are building these AIs Yeah. Are taking seriously and coordinating around best practices That’s right. With respect to, these critical matters. That’s right. Exactly. And so so that’s under celebrated, under understood. Yes. Somebody needs to to to, well, everybody needs to start talking about AI as a system of AIs and system of of engineered systems, engineered systems that are that are well engineered, built from first principles, well tested, so on and so forth. Regulation. Remember remember AI is a capability that can be applied. And and don’t it’s necessary to to have regulation for important technologies but it’s it’s also don’t don’t don’t overreach to the point where some of the regulation ought to be done most of the regulation ought to be done at the applications. Right. The FAA, NHTSA, FDA, you name it. Right? All of the different all of the different ecosystems that already regulate applications of technology Right. Now have to regulate the application of technology that is now infused with AI. Right. And so and so I think I think, there’s don’t don’t don’t misunderstand, don’t overlook the overwhelming amount of regulation in the world Right. That are gonna have to be activated for AI. And don’t rely on just one universal galactic Right. You know, AI council that’s gonna possibly be able to do this because there’s a reason why all of these different agencies were created. There was there’s a reason why all these different, regulatory bodies were created. We’ll go back to first principles again. I’d get in trouble by my partner, Bill Gurley, if I didn’t go back to the open source point. You guys launched a very important, very large, very capable open source model. Yeah. Yeah. Recently. Yep. Obviously, Meta is making significant contributions to open source. I find when I read Twitter, you know, you have this kind of open versus closed a lot of a lot of, chatter about it. How do you feel about open source your own open source models ability to keep up Mhmm. With Frontier. Mhmm. That would be the first question. The second question would be is that, you know, having that open source model and also having closed, source models, you know, that are powering commercial operations. Is that what you see into the future and do those two things, does that create the healthy tension for safety? Mhmm. Open source versus closed source is related to safety, but not only about safety. You know? And so so, for example, there there’s absolutely nothing wrong with having closed source models that are that are the engines of an economic model Exactly. Necessary to sustain innovation. Right. Okay. I celebrate that wholeheartedly. Right. It is it is it is, I believe, wrong minded to be, closed versus open. Right. It should be closed and open. Plus open. Yeah. Right. Because open is necessary for many industries to be activated. Right now, if we didn’t have open source, how would all these different fields of science be able to activate be activated on AI? Right. Right? Because they have to develop their own domain specific AIs and and they have to develop their own using open source models, create domain specific AIs. They’re related, again, not the same. Right. Just because you have an open source model doesn’t mean you have an AI. And so you have to have that open source model to enable the creation of AIs. So financial services, health care, transportation, the list of industries, fields of science that has now been enabled as a result of open source, Unbelievable. Are you seeing a lot of demand for your open source models? Our open source models so first of all, Llama downloads. Right? Obviously. Yeah. Mark and the work that they’ve they’ve done, incredible. Off the charts. Yes. And it completely activated and and, engaged every single industry, every single field of science. Right. Okay. That’s terrific. The reason why we did NemoTron was for, synthetic data generation. Mhmm. Intuitively, the idea that one AI would would somehow sit there and loop and generate data to learn itself, it sounds it sounds brittle. And and, how many times you can go around that infinite loop that loop, you know, questionable. However, it’s kinda my mental image is kinda like like, you get a super smart person, put him into a a padded room, close the door for about a month. You know, what what comes out is probably not not a smarter person. And and so so but the idea that you could have have 2 or 3 people sit around and we have we have different AIs, we have different distributions of knowledge, and we can go QA back and forth. All 3 of us can come out smarter. Right. And so the idea that you can have AI models exchanging, interacting, going back and forth, debating, reinforcement learning, synthetic data generation, for example, kind of intuitively makes sense. Suggest and makes sense. Yeah. And so our model, Nemo Tron 350 B is 340 B is is the best model in the world for reward systems. And so it is the best critique. Okay. Interesting. Yeah. And so so, a fantastic model for enhancing everybody else’s model. So irrespective of how how great somebody else’s model is Right. I’d have recommend using Nemo Tron 3 40 b to enhance and make it better and we’ve already seen made llama better, made all the other models better. Well, we’re coming to the end. Thank goodness. As somebody who delivered dgx1 in 2016, It’s really been an incredible journey. Your journey is unlikely and incredible at the same time. Thank you. You survived. Like just surviving the early days was pretty extraordinary. You delivered the first d g x one in 2016. Mhmm. We had this Cambrian moment in 2022. And so I’m gonna ask you the question I often get answer get asked, which is how long can you sustain what you’re doing today? With 60 direct reports. Mhmm. You’re everywhere. Mhmm. You’re driving this revolution. Mhmm. Are you having fun? And is there something else that you would rather be doing? This is a question about the last hour and a half. The answer is I had great I had a great time I had a great time. I couldn’t imagine anything else I’d rather be doing. Let’s see. I think it’s I don’t think it’s right to leave the impression that that our our job is fun all the time. Right. My job isn’t fun all the time nor nor do I expect it to be fun all the time. Was that ever an expectation that it was fun all the time? I think it’s important all the time. Yeah. I take I don’t take myself too seriously. I take the work very seriously. I take our responsibility very seriously. I take our contribution and our moment in time very seriously. Is that always fun? No. Yeah. But do I always love it? Yes. Yeah. Like all things. You know, whether it is is family, friends, children, is it always fun? No. Do we always love it? Absolutely, deeply. And so so I think the the, how long can I do this, The real question is how long can I be relevant? And that only matters that that piece of information, that question can only be answered with how how am I gonna continue to learn. And I am a lot more optimistic today. I’m not saying this simply because of our topic today. I’m a lot more optimistic about my ability to stay relevant and continue to learn because of AI. Yeah. I use it I don’t know, but I’m sure you guys do. I use it literally every day. Literally. There’s not one piece of research that I don’t involve AI with. Yeah. There’s not one question that I even if I know the answer, I double check on it with AI and surprisingly, you know, the next 2 or 3 questions I ask it reveals something I didn’t know. That’s right. You pick your topic. Right. You pick your topic. And and I think that that, AI as a tutor, AI as an assistant, AI as a, you know, a a partner to brainstorm with, double check my work. Right. You know, boy, you guys it’s completely revolutionary. Yeah. And that’s just you know, I’m an information worker. I’m you know, my output is information, and and so I think the the, the contributions that that all have on society is is pretty extraordinary. So so I think I think the if that’s the case, if I could stay relevant like this, and I can continue to make a contribution, I know I know that the the work is important enough for me to wanna continue to pursue it, and and my my quality of life is incredible. So, I mean, what’s your I’ll say, I can’t imagine you and I have been at this for a few decades. I can’t imagine missing this moment. Yeah. Right. It’s the most consequential moment of our careers. We’re deeply grateful for the partnership. Don’t miss the next 10 years. For the thought partnership. Yeah. You make us smarter. Thank you. And I think you’re really important, as part of the leadership, right, that’s going to optimistically and safely lead this forward. So thank you for being with us. Really enjoyed it. Really. Thanks Brad, thanks Clark. Good job. As a reminder to everybody, just our opinions, not investment advice.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define an function for regular API Call"
      ],
      "metadata": {
        "id": "zdtzYu20W9kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_api_call():\n",
        "  messages = [\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "              {\n",
        "                  \"type\": \"text\",\n",
        "                  \"text\": \"<transcript>\" + content + \"</transcript>\",\n",
        "              },\n",
        "              {\n",
        "                  \"type\": \"text\",\n",
        "                  \"text\": \"Who is the interviewee of this interview? Only output the name\"\n",
        "              }\n",
        "          ]\n",
        "      }\n",
        "  ]\n",
        "\n",
        "  start_time = time.time()\n",
        "  response = client.messages.create(\n",
        "      model=\"claude-3-5-sonnet-latest\",\n",
        "      max_tokens=300,\n",
        "      messages=messages,\n",
        "  )\n",
        "  end_time = time.time()\n",
        "\n",
        "  return response, end_time - start_time"
      ],
      "metadata": {
        "id": "0RkwJKH7TqpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define an function for Cached API Call"
      ],
      "metadata": {
        "id": "fkrPajowXDXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_cached_api_call():\n",
        "  messages = [\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "              {\n",
        "                  \"type\": \"text\",\n",
        "                  \"text\": \"<transcript>\" + content + \"</transcript>\",\n",
        "                  \"cache_control\": {\"type\": \"ephemeral\"}\n",
        "              },\n",
        "              {\n",
        "                  \"type\": \"text\",\n",
        "                  \"text\": \"Who is the interviewee of this interview? Only output the name\"\n",
        "              }\n",
        "          ]\n",
        "      }\n",
        "  ]\n",
        "\n",
        "  start_time = time.time()\n",
        "  response = client.messages.create(\n",
        "      model=\"claude-3-5-sonnet-latest\",\n",
        "      max_tokens=300,\n",
        "      messages=messages,\n",
        "      extra_headers={\"anthropic-beta\":\"prompt-caching-2024-07-31\"}\n",
        "  )\n",
        "  end_time = time.time()\n",
        "\n",
        "  return response, end_time - start_time\n"
      ],
      "metadata": {
        "id": "T37GxxnlVru2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare the difference"
      ],
      "metadata": {
        "id": "qdcfcn6_XGTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response, call_time = make_api_call()\n",
        "\n",
        "print(f\"API call time: {call_time:.2f} seconds\")\n",
        "print(f\"API call input tokens: {response.usage.input_tokens}\")\n",
        "print(f\"API call output tokens: {response.usage.output_tokens}\")\n",
        "\n",
        "print(\"\\nResult:\")\n",
        "print(response.content)\n",
        "\n",
        "cached_response, cached_time = make_cached_api_call()\n",
        "\n",
        "print(f\"Cached API call time: {cached_time:.2f} seconds\")\n",
        "print(f\"Cached API call input tokens: {cached_response.usage.input_tokens}\")\n",
        "print(f\"Cached API call output tokens: {cached_response.usage.output_tokens}\")\n",
        "\n",
        "print(\"\\nResult:\")\n",
        "print(cached_response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da8QzDAuWrRB",
        "outputId": "6b0fb562-0a02-4258-aecf-6b7f7fecfd18"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API call time: 2.43 seconds\n",
            "API call input tokens: 18234\n",
            "API call output tokens: 20\n",
            "\n",
            "Result:\n",
            "[TextBlock(text='The interviewee is Jensen Huang, who is the CEO of NVIDIA.', type='text')]\n",
            "Cached API call time: 1.41 seconds\n",
            "Cached API call input tokens: 18\n",
            "Cached API call output tokens: 17\n",
            "\n",
            "Result:\n",
            "[TextBlock(text='Jensen Huang, the CEO and co-founder of NVIDIA.', type='text')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UFiUJXMoWsEG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}